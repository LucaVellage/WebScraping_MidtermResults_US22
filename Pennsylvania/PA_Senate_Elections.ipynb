{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pennsylvania Senate Elections 2022  \n",
    "This script is scraping the 2022 midterm election results of the Senate elections in Pennsylvania. For now, it is scraping the winning party (i.e. with the highest win margin) per state from CNN.  \n",
    "\n",
    "Source: https://edition.cnn.com/election/2022/results/pennsylvania/senate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to scrape Wrappers with midterm senate election results in PA per county\n",
    "\n",
    "def senate_election_results(soup):\n",
    "    # Locating + getting relevant table content\n",
    "    senate_win = soup.find_all(\"article\", class_=\"core-result cnn-pcl-1hnl3l7\")\n",
    "\n",
    "    # Initializing empty list to store results\n",
    "    senate_win_list = []\n",
    "\n",
    "    for result in senate_win:\n",
    "        try:\n",
    "            county = result.find(class_=\"header-2-AOgLYo cnn-pcl-xk8c6r\").get_text()\n",
    "        except:\n",
    "            county = \"\"\n",
    "        try:\n",
    "            winning_party = result.find(class_=\"party-label-239xt1 cnn-pcl-1me6450\").get_text()\n",
    "        except:\n",
    "            winning_party = \"\"\n",
    "          \n",
    "        # Appending the scraped data to the previously initialised list as a dictionary\n",
    "        senate_win_list.append({\"County\": county, \"Senate_Winning_Party\": winning_party})\n",
    "\n",
    "    return senate_win_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages found.\n",
      "Data has been written to senate_win_list.csv.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Setting up Selenium\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://edition.cnn.com/election/2022/results/pennsylvania/senate\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "    #Initialising list to store data from all pages\n",
    "    all_senate_win_list = []\n",
    "\n",
    "    try:\n",
    "        for _ in range(8):  \n",
    "            # Waittime of 10 seconds before automatically clicking the next button to ensure page is fully loaded\n",
    "            #Note: Cookie Pop-up must be accepted/rejected manually!\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"core-result.cnn-pcl-1hnl3l7\"))\n",
    "            )\n",
    "\n",
    "            # Parsing, extracting and storing relevant information from current web page \n",
    "            current_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            current_page_data = senate_election_results(current_soup)\n",
    "            all_senate_win_list.extend(current_page_data)\n",
    "\n",
    "            # Automatically clicking button to navigate to next page if it exists \n",
    "            next_buttons = driver.find_elements(By.CLASS_NAME, \"rightButton.cnn-pcl-13b0kh1\")\n",
    "            if next_buttons:\n",
    "                next_button = next_buttons[0]  \n",
    "                next_button.click()\n",
    "\n",
    "                #wait time of 5 seconds for next page to load\n",
    "                time.sleep(5)  \n",
    "\n",
    "            # End of pages, i.e no more next button found\n",
    "            else:\n",
    "                print(\"No more pages found.\")\n",
    "                break\n",
    "\n",
    "    #Error handling or no more pages         \n",
    "    except Exception as e:\n",
    "        print(\"Navigation error or no more pages:\", e)\n",
    "\n",
    "    # Exporting aggregated data to csv\n",
    "    csv_file_path = \"senate_win_list.csv\"\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"County\", \"Senate_Winning_Party\"])\n",
    "        writer.writeheader()\n",
    "        for row in all_senate_win_list:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Data has been written to {csv_file_path}.\")\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
